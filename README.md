<h1 align='center'>
Metascale - Cicada
</h1>
<p align="center">
  <a href="" rel="noopener">
 <img width=350px height=200px src="https://i.imgur.com/oXHVMKJ.png" alt="Project logo"></a>
</p>

<div align="center">

[![Status](https://img.shields.io/badge/status-active-success.svg)]()
[![GitHub Issues](https://img.shields.io/github/issues/kylelobo/The-Documentation-Compendium.svg)](https://github.com/kylelobo/The-Documentation-Compendium/issues)
[![GitHub Pull Requests](https://img.shields.io/github/issues-pr/kylelobo/The-Documentation-Compendium.svg)](https://github.com/kylelobo/The-Documentation-Compendium/pulls)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](/LICENSE)

</div>

## üìù √çndice

- [üßê Arquitetura](#-arquitetura)
  - [Metascale](#metascale)
  - [Funcionamento da Solu√ß√£o](#funcionamento-da-solu√ß√£o)
  - [Carregamento e Processamento Inicial no DynamoDB](#carregamento-e-processamento-inicial-no-dynamodb)
  - [Fall-Back do Lambda](#fall-back-do-lambda)
  - [Garantindo a Sincroniza√ß√£o Autom√°tica do DynamoDB](#garantindo-a-sincroniza√ß√£o-autom√°tica-do-dynamodb)
  - [Captura de Altera√ß√µes (CDC) com Debezium e Kafka](#captura-de-altera√ß√µes-cdc-com-debezium-e-kafka)
    - [1. Captura de Altera√ß√µes (CDC) com Debezium](#1-captura-de-altera√ß√µes-cdc-com-debezium)
    - [2. Publica√ß√£o de Eventos no Kafka](#2-publica√ß√£o-de-eventos-no-kafka)
    - [3. Processamento dos Dados pelo Metascale](#3-processamento-dos-dados-pelo-metascale)
    - [4. Envio dos Dados ao DynamoDB](#4-envio-dos-dados-ao-dynamodb)
  - [Falta de Informa√ß√£o no DynamoDB](#falta-de-informa√ß√£o-no-dynamodb)
  - [Gerenciamento de Atualiza√ß√µes e Concorr√™ncia](#gerenciamento-de-atualiza√ß√µes-e-concorr√™ncia)
  - [Regras e Restri√ß√µes](#regras-e-restri√ß√µes)
  - [Resumo](#resumo)
- [Requisitos](#requisitos)
- [Instala√ß√£o](#instala√ß√£o)
- [Tecnologias Utilizadas](#techs)
- [Uso](#uso)
- [Funcionalidades](#funcionalidades)
- [Capturas de Tela](#capturas-de-tela)
- [Contribui√ß√£o](#contribui√ß√£o)
- [Autores](#autores)
- [Licen√ßa](#licen√ßa)
- [Agradecimentos](#agradecimentos)

## üßê Arquitetura [üîù](#arquitetura)

### Metascale
O nome da nossa solu√ß√£o, **Metascale**, origina da ideia de **metadados e escalabilidade**, em que nos baseamos nesses metadados para associar os retornos dos diferentes sistemas heterog√™neos da Vivo, com um modelo can√¥nico homogeneizado.

De forma que a partir desse modelo can√¥nico, conseguimos salvar as informa√ß√µes para um retorno perform√°tico e escal√°vel atrav√©s de solu√ß√µes **Cloud da AWS**, como o *Lambda* e o *DynamoDB*, em que *JSON‚Äôs ‚Äúprontos‚Äù* preparados a partir do can√¥nico s√£o registrados no Dynamo, e o Lambda, por ser uma solu√ß√£o serverless, trataria as necessidades de performance e escalabilidade automaticamente, respondendo aos picos conforme a necessidade.

Entrando em detalhes no que chamamos de metadados, um exemplo de uso seria associar o atributo *‚Äúdescription‚Äù* do JSON retornado no servi√ßo XYZ da Vivo, com o atributo *‚Äúdescri√ß√£o‚Äù* do modelo can√¥nico *‚ÄúProduto‚Äù*. A vantagem dessa abordagem est√° na facilidade de associa√ß√£o de novos servi√ßos com a solu√ß√£o, e suas evolu√ß√µes, tendo em vista que em outro servi√ßo de produto, o nome do atributo correspondente √† *‚Äúdescri√ß√£o‚Äù* do can√¥nico, poderia ter o nome *‚Äúdesc‚Äù*. Da mesma forma, caso surja a necessidade de usar algum outro atributo, bastaria alterar o metadado da solu√ß√£o e funcionaria sem nenhum problema, o que n√£o seria poss√≠vel ao acoplar os retornos de ambos servi√ßos √† solu√ß√£o.

Assim como comentado na apresenta√ß√£o do desafio, a palavra-chave estaria em *‚ÄúDesacoplamento‚Äù*, e foi o que buscamos com o **Metascale**.

<h3 align="center">Desenho da solu√ß√£o</h3>

<div align="center">
	<img src="https://github.com/user-attachments/assets/772788f2-d145-4359-ab7a-aab94447d9ff" />
</div>

### Funcionamento da Solu√ß√£o

### Carragamento e Processamento Inicial no DynamoDB

Quando a informa√ß√£o solicitada pelo cliente no **App Vivo** j√° est√° carregada e pronta no **DynamoDB**, o componente denominado **Metascale** j√° teria processado as informa√ß√µes dos produtos do cliente atrav√©s de um processo de **ETL**. Nesse processo, requisi√ß√µes *GET* s√£o disparadas para os sistemas da Vivo com o objetivo de obter todos os dados necess√°rios previamente, associando e tratando as informa√ß√µes utilizando os metadados e montando o modelo can√¥nico correspondente.

### Fall-Back do Lambda

Entretanto, caso a informa√ß√£o n√£o esteja dispon√≠vel no **DynamoDB**, o Lambda possui um mecanismo de *fall-back*. Nesse cen√°rio, o Lambda chama a API do Metascale (este projeto) para realizar todo o processo de ETL. A API √© respons√°vel por buscar o modelo can√¥nico correspondente, recuperar as informa√ß√µes nas aplica√ß√µes *blackbox* da Vivo e montar o resultado para exibi√ß√£o ao cliente.

Antes que a informa√ß√£o fique pronta, pode ser necess√°rio realizar alguns tratamentos espec√≠ficos no *payload*. Para esses casos, criamos outra aplica√ß√£o, dispon√≠vel no [reposit√≥rio Metascale Builder](https://github.com/pedroargentati/metascale-builder), que permite que os pr√≥prios desenvolvedores da Vivo possam:

- **Modificar e realizar p√≥s-processamento no payload:** Utilizando o m√©todo `build`, os desenvolvedores podem realizar qualquer tipo de modifica√ß√£o no *payload*.
- **Extrair dados dos par√¢metros necess√°rios:** Com o m√©todo `extract`, √© poss√≠vel extrair os dados necess√°rios diretamente do *payload*.
- **Realizar o *merge* de can√¥nicos:** O m√©todo `merge` permite juntar *n* can√¥nicos, da forma que o desenvolvedor preferir.

Essa arquitetura garante que as informa√ß√µes sejam corretamente tratadas e apresentadas ao cliente, independentemente de estarem dispon√≠veis diretamente no **DynamoDB** ou exigirem o processamento adicional do **Metascale**.

A partir desse disparador, conseguimos ter a garantia de que a informa√ß√£o do **DynamoDB** sempre estar√° atualizada e pronta para retorno ao cliente. De forma que no cen√°rio atual, **apenas seria necess√°rio retornar um JSON ou montar a informa√ß√£o a partir de outros JSON(s) j√° carregado(s)** da informa√ß√£o desejada ao App Vivo para visualiza√ß√£o do cliente, atrav√©s das fun√ß√µes Lambda da *AWS* acessando o **DynamoDB** diretamente.

### Garantindo a Sincroniza√ß√£o autom√°tica do DynamoDB

No cen√°rio em que o cliente alterou alguma informa√ß√£o relacionada aos seus produtos, o App da Vivo teria se comunicado diretamente com seus sistemas para requisi√ß√µes de atualiza√ß√£o, contornando a nossa solu√ß√£o. Todavia caso o cliente esteja contratando um novo produto, por exemplo, a nossa solu√ß√£o deveria ser capaz de retornar a informa√ß√£o atualizada ap√≥s a finaliza√ß√£o da requisi√ß√£o de atualiza√ß√£o, de forma que n√£o bastaria aguardar uma atualiza√ß√£o do DynamoDB sem que nenhum sistema avisasse a nossa solu√ß√£o.

## Captura de Altera√ß√µes (CDC) com Debezium e Kafka

1. **Captura de Altera√ß√µes (CDC) com Debezium**:
   - O **Debezium** √© um componente de captura de mudan√ßas (*Change Data Capture* - CDC) que monitora os bancos de dados dos sistemas da Vivo. Ele √© respons√°vel por detectar altera√ß√µes (inser√ß√µes, atualiza√ß√µes e exclus√µes) em tempo real.
   - Sempre que ocorre uma mudan√ßa nos sistemas Vivo (representados como *black-box*), o **Debezium** extrai essas informa√ß√µes e transforma as mudan√ßas em eventos de dados.
   - Caso o cliente esteja contratando um novo produto, por exemplo, a nossa solu√ß√£o ser√° capaz de retornar a informa√ß√£o atualizada ap√≥s a finaliza√ß√£o da requisi√ß√£o de atualiza√ß√£o, de forma que n√£o bastaria aguardar uma atualiza√ß√£o do **DynamoDB** sem que nenhum sistema avisasse a nossa solu√ß√£o.

2. **Publica√ß√£o de Eventos no Kafka**:
   - Ap√≥s a captura das mudan√ßas, o **Debezium** publica esses eventos em t√≥picos do **Kafka**, que est√° conectado ao componente **Metascale**. O **Kafka** funciona como um sistema de mensageria distribu√≠do, permitindo o gerenciamento eficiente de grandes volumes de dados em tempo real.
   - Esses eventos publicados no **Kafka** representam os dados que precisam ser processados pelo pr√≥ximo componente na arquitetura.

3. **Processamento dos Dados pelo Metascale**:
   - O **Kafka**, ao receber os eventos do **Debezium**, dispara as mensagens para a aplica√ß√£o **Metascale**. O **Metascale** √© respons√°vel por processar os dados recebidos, realizando as transforma√ß√µes necess√°rias no contexto de um processo **ETL** (Extract, Transform, Load).
   - O **Metascale** trata os dados, aplicando a l√≥gica de neg√≥cio, e os prepara em um formato can√¥nico que ser√° posteriormente consumido pelo sistema final.

4. **Envio dos Dados ao DynamoDB**:
   - Ap√≥s o processamento dos dados pelo **Metascale**, o resultado √© enviado para o banco de dados **DynamoDB**. Esse banco de dados armazena os dados transformados de forma eficiente e otimizada para consultas futuras.
   - Sempre que o **App Vivo** fizer uma solicita√ß√£o de informa√ß√µes, o **Lambda** ir√° consultar o **DynamoDB** para buscar as informa√ß√µes j√° processadas. Caso os dados n√£o estejam dispon√≠veis, o **Lambda** acionar√° o **Metascale** novamente para buscar as informa√ß√µes e realizar o ETL.

Com isso, a Vivo seria capaz de avisar a nossa solu√ß√£o sem a necessidade de altera√ß√£o em seu c√≥digo fonte, apenas configurando essa estrutura conforme a necessidade. Garantindo assim que, de forma ass√≠ncrona, os dados atualizados dos clientes da Vivo sejam carregados novamente no **DynamoDB** com a performance e a lat√™ncia necess√°ria, atrav√©s do processamento do **Debezium** e do andamento da mensageria **Kafka**.

## Merge dos Can√¥nicos

O processo de **merge** (fus√£o) dos can√¥nicos √© essencial quando os dados do modelo can√¥nico s√£o compostos por informa√ß√µes que v√™m de m√∫ltiplas fontes ou "dimens√µes". Essas dimens√µes podem representar diferentes tabelas ou sistemas, como uma tabela de produtos e uma tabela de planos de pagamento, por exemplo.

### Cen√°rio

Suponha que tanto a tabela de produtos quanto a de planos de pagamento possuam um atributo em comum, como o campo `description`. Em vez de atualizar manualmente todas as ocorr√™ncias desse atributo em cada dimens√£o de forma separada, o m√©todo **merge** no componente `canonical-builder` facilita a integra√ß√£o dessas informa√ß√µes de forma unificada.

### Como Funciona

Quando o **merge** √© executado:

1. **Busca e Integra√ß√£o de Dados**: O m√©todo realiza uma busca em todas as dimens√µes que compartilham o mesmo atributo (por exemplo, o campo `description`).
   
2. **Unifica√ß√£o**: Ele consolida esses dados em uma √∫nica resposta, retornando a informa√ß√£o unificada e atualizada. Isso evita redund√¢ncias e inconsist√™ncias, garantindo que a informa√ß√£o apresentada seja coerente e completa, considerando todas as fontes de dados.

3. **Otimiza√ß√£o**: Em vez de realizar m√∫ltiplas consultas ou atualiza√ß√µes em cada sistema ou tabela separadamente, o **merge** simplifica esse processo ao permitir uma √∫nica chamada que agrega as informa√ß√µes de todas as dimens√µes relevantes.

### Vantagens do Merge

- **Efici√™ncia**: O processo de fus√£o automatiza a busca e atualiza√ß√£o dos dados, economizando tempo e reduzindo a complexidade do c√≥digo.
  
- **Coer√™ncia dos Dados**: Ao consolidar as informa√ß√µes de diferentes fontes, o m√©todo garante que os dados sejam coerentes, eliminando o risco de inconsist√™ncias entre sistemas.
  
- **Escalabilidade**: Conforme o n√∫mero de fontes e dimens√µes aumenta, o m√©todo **merge** continua a fornecer uma solu√ß√£o escal√°vel, permitindo a fus√£o eficiente de dados sem a necessidade de atualiza√ß√µes manuais.

### Exemplo de Uso

Vamos considerar um exemplo pr√°tico:

- O can√¥nico cont√©m informa√ß√µes sobre produtos e planos de pagamento.
- Tanto o produto quanto o plano de pagamento t√™m o atributo `description`.
  
Usando o m√©todo **merge**, voc√™ pode unificar a `description` de ambas as dimens√µes em uma √∫nica resposta, garantindo que os dados corretos de ambas as fontes sejam retornados de maneira integrada.


## Falta de Informa√ß√£o no DynamoDB

No cen√°rio em que a informa√ß√£o solicitada ainda n√£o est√° carregada no **DynamoDB**, pois o processo n√£o priorizou o seu carregamento previamente, surge o pior cen√°rio da solu√ß√£o. Nele, por motivos inesperados, algum cliente que n√£o tenha sido priorizado tenta acessar o **App Vivo**, necessitando aguardar que o **Metascale** realize o carregamento da informa√ß√£o completa nos sistemas da Vivo.

Nesse caso, o tempo de espera seria semelhante ao anterior √† solu√ß√£o, acrescido do tempo necess√°rio para o processo de ETL do **Metascale**, que pode ou n√£o ser capaz de otimizar a busca de informa√ß√µes. Isso depender√° se determinadas buscas nos sistemas da Vivo envolvem informa√ß√µes n√£o diretamente ligadas ao novo cliente, mas a outros dados, como informa√ß√µes relacionadas a produtos sem associa√ß√£o direta a um cliente espec√≠fico.

Esperamos que esse cen√°rio n√£o ocorra com frequ√™ncia. No entanto, caso ocorra, a expectativa √© que apenas esse primeiro carregamento seja demorado, n√£o apresentando problemas de lat√™ncia ap√≥s a primeira carga ser realizada no **DynamoDB**.

## Gerenciamento de Atualiza√ß√µes e Concorr√™ncia

Nesses casos, o que ocorre √© que, enquanto o **Metascale** n√£o tenha recebido o aviso origin√°rio do **Debezium**, ele retornar√° a informa√ß√£o ainda localizada no **DynamoDB**. No entanto, assim que o **Metascale** consome o "t√≥pico" da fila do **Kafka**, indicando uma atualiza√ß√£o de informa√ß√£o, ele invalidar√° o registro do **DynamoDB**, disparando um processo eficiente de atualiza√ß√£o apenas das informa√ß√µes alteradas, at√© que o registro esteja coerente com a informa√ß√£o mais atual.

Esse comportamento pode ser associado com uma transa√ß√£o de banco de dados, em que enquanto o "commit" final dos sistemas da Vivo n√£o tenha acontecido, a informa√ß√£o anterior ser√° retornada. Ap√≥s o "commit", ela seria atualizada e retornada com as informa√ß√µes novas. Apesar do risco de um retorno parcial das informa√ß√µes mais recentes, a arquitetura atual da Vivo, que trabalha com microsservi√ßos, j√° considera o assincronismo como uma consequ√™ncia, dado que depende de diversos bancos de dados para a mesma informa√ß√£o.

Para mitigar esses casos, uma possibilidade seria investigar mais a fundo os logs analisados pelo **Debezium**, utilizando flags estrat√©gicas para indicar altera√ß√µes de informa√ß√£o e garantir que a atualiza√ß√£o ocorra antes de qualquer retorno. Outra abordagem seria a implementa√ß√£o de **Webhooks** como alternativa para disparar eventos que notificam a finaliza√ß√£o da altera√ß√£o.

## Regras e Restri√ß√µes

- Depend√™ncia do funcionamento da AWS.
- Depend√™ncia com os sistemas da Vivo para carregamento de informa√ß√µes.
- Necessidade de implementar o Debezium corretamente para os avisos de CDC, configurando as conex√µes com as bases de dados da Vivo.
- Necessidade de configurar os metadados corretamente para sincronizar os sistemas com o Metascale.
- Se houver a necessidade de adicionar algum tipo de tratamento personalizado ao modelo can√¥nico a ser montado, ser√° necess√°rio configurar os servi√ßos de customiza√ß√£o adequadamente.

## Resumo

Esse fluxo garante que as altera√ß√µes nos dados dos sistemas da Vivo sejam capturadas em tempo real pelo **Debezium**, publicadas no **Kafka** e processadas pelo **Metascale**, que depois armazena o resultado no **DynamoDB** para ser consumido de forma otimizada pelo **App Vivo**. O sistema √© altamente escal√°vel e responsivo, garantindo a integridade e disponibilidade dos dados para os clientes da Vivo.

## Requisitos Funcionais e N√£o Funcionais

| N¬∞    | Requisito                                                     | Descri√ß√£o                                                                                     | Status    |
|-------|---------------------------------------------------------------|-------------------------------------------------------------------------------------------------|-----------|
| RF01  | Buscar informa√ß√µes no sistema da Vivo                         | Habilita a busca de informa√ß√µes nos sistemas Vivo.                                               | ‚úîÔ∏è        |
| RF02  | Atualizar informa√ß√µes conforme sistemas da Vivo               | O Metascale mant√©m a coer√™ncia dos dados √† medida que os sistemas da Vivo os atualizam.          | ‚úîÔ∏è        |
| RF03  | Carregar lote de dados                                        | O Metascale carrega em lotes as informa√ß√µes dos sistemas da Vivo.                                | ‚úîÔ∏è        |
| RF04  | Atualizar metadados                                           | O sistema recebe atualiza√ß√µes nos metadados para manter a comunica√ß√£o precisa entre os sistemas. | ‚úîÔ∏è        |
| RF05  | Personalizar informa√ß√µes com regras de neg√≥cio e tratamentos  | √â poss√≠vel adicionar tratamentos personalizados aos dados salvos no Metascale.                  | ‚úîÔ∏è        |
| RF06  | Monitorar o funcionamento da solu√ß√£o                          | Acesso a fun√ß√µes de monitoramento e observabilidade √© essencial para a solu√ß√£o.                  | ‚úîÔ∏è        |
| RF07  | Corrigir informa√ß√µes dos clientes no Metascale                | Possibilitar manuten√ß√µes nos dados do Metascale.                                                 | ‚úîÔ∏è        |
| RF08  | Avisos e alertas de situa√ß√µes at√≠picas do sistema             | Implementar avisos e alertas em situa√ß√µes at√≠picas, como picos de chamadas.                      | ‚úîÔ∏è        |
| RNF01 | Gest√£o de Dados Can√¥nicos                                     | Integra√ß√£o de dados de fontes legadas, garantindo homogeneiza√ß√£o e padroniza√ß√£o.                 | ‚úîÔ∏è        |
| RNF02 | Desempenho de Pico                                             | Mant√©m alta disponibilidade e desempenho, suportando at√© 15 mil chamadas por minuto por API.     | ‚úîÔ∏è        |
| RNF03 | Baixa lat√™ncia para acesso √†s informa√ß√µes de bases externas    | Atualiza√ß√µes de dados ocorrem em at√© 15 minutos no sistema Metascale.                            | ‚úîÔ∏è        |
| RNF04 | Escalabilidade Sem Impacto                                     | Capaz de expandir capacidade e funcionalidades sem impactar o desempenho atual.                  | ‚úîÔ∏è        |
| RNF05 | Conformidade Regulat√≥ria                                       | Conforme regulamentos de prote√ß√£o de dados, como GDPR, LGPD, entre outros.                       | ‚úîÔ∏è        |
| RNF06 | Performance de resposta                                        | Responder √†s requisi√ß√µes dos clientes em at√© 80ms.                                               | ‚úîÔ∏è        |
| RNF07 | Uso de tecnologias modernas e est√°veis                        | Tecnologias modernas e est√°veis reduzem riscos e simplificam manuten√ß√£o.                        | ‚úîÔ∏è        |
| RNF08 | Resili√™ncia e toler√¢ncia a falhas                              | Tratamentos implementados para cen√°rios de falhas, desastres e sobrecarregamento.                | ‚úîÔ∏è        |

RF: Requisitos Funcionais.  
RNF: Requisitos N√£o Funcionais.

## Requisitos [üîù](#requisitos)

- Node.js (vers√£o 14 ou superior)
- npm (ou yarn)
- Docker Desktop

## üéà Instala√ß√£o [üîù](#instala√ß√£o)

### 1. Clonar o reposit√≥rio

Execute o comando abaixo no terminal para clonar o reposit√≥rio:

```bash
git clone https://github.com/pedroargentati/metascale.git
```

### 2. Acessar o diret√≥rio do projeto

Navegue at√© o diret√≥rio do projeto clonado:

```bash
cd metascale
```

### 3. Instalar as depend√™ncias

```bash
npm install
```
ou
```bash
yarn install
```
### 4. Configurar vari√°veis de ambiente

Crie o arquivo `.env` seguindo o template abaixo:
```env
PORT={API_PORT}

AWS_ACCESS_KEY_ID={ACCESS_KEY}
AWS_SECRET_ACCESS_KEY={SECRET_KEY}
AWS_REGION=us-east-2

KAFKA_CLIENT_ID=metascale
KAFKA_BROKERS={host-kafka}:{port-kafka}
KAFKA_GROUP_ID=metascale-group

KAFKAJS_NO_PARTITIONER_WARNING=1

INSTANCE_TYPE={API ou KAFKA}

DEV_MODE=true
```

### 5. Modos de Inicializa√ß√£o da Aplica√ß√£o

#### API

- Um servidor Express ser√° inicializado na porta configurada nas vari√°veis de ambiente (caso esteja configurada), ou, por padr√£o, na porta `8080`.
- Todas as chamadas √† API estar√£o dispon√≠veis ap√≥s a inicializa√ß√£o. Para mais detalhes sobre os endpoints e funcionalidades, acesse a [Documenta√ß√£o da API](http://localhost:8080/api-docs/#/).

#### Kafka

- Ao ser inicializada, a aplica√ß√£o busca todos os can√¥nicos cadastrados no DynamoDB. Para cada t√≥pico associado ao respectivo can√¥nico, a aplica√ß√£o ir√° se inscrever nesses t√≥picos e consumir todas as mensagens dispon√≠veis.
- Ap√≥s consumir as mensagens, a aplica√ß√£o dispara o m√©todo `synchronize` do projeto **canonical-builder**, que √© respons√°vel por sincronizar as informa√ß√µes consumidas.
- **Aten√ß√£o**: Certifique-se de que o servidor Kafka est√° em execu√ß√£o corretamente e que as configura√ß√µes no arquivo `.env` est√£o corretas.

## 6. Rodar o Projeto

Para iniciar o projeto, siga os passos abaixo:

1. **Entrar na Pasta de Infraestrutura**
```bash
cd infra
```
2. **Dentro da pasta infra, navegue at√© a pasta `local`:**
```bash
cd local
```
3. **Execute o script `setup.bat` para configurar e iniciar as imagens Docker necess√°rias:**
```bash
setup.bat
```
Certifique-se de que voc√™ tenha o Docker instalado e configurado corretamente em sua m√°quina antes de executar o script.


## Tecnologias Utilizadas
<div align="center">
<img src="https://img.shields.io/badge/TypeScript-007ACC?style=for-the-badge&logo=typescript&logoColor=white" />
<img src="https://img.shields.io/badge/Node%20js-339933?style=for-the-badge&logo=nodedotjs&logoColor=white" />
<img src="https://img.shields.io/badge/Express%20js-000000?style=for-the-badge&logo=express&logoColor=white"/>
<img src="https://img.shields.io/badge/ts--node-3178C6?style=for-the-badge&logo=ts-node&logoColor=white" />
<img src="https://img.shields.io/badge/Apache_Kafka-231F20?style=for-the-badge&logo=apache-kafka&logoColor=white"/>
<img src="https://img.shields.io/badge/Amazon AWS-FF9900?style=for-the-badge&logo=amazonaws&logoColor=white" />
<img src="https://img.shields.io/badge/Docker-2CA5E0?style=for-the-badge&logo=docker&logoColor=white"/>
<img src="https://img.shields.io/badge/Amazon%20DynamoDB-4053D6?style=for-the-badge&logo=Amazon%20DynamoDB&logoColor=white" />
<img src="https://img.shields.io/badge/Grafana-F2F4F9?style=for-the-badge&logo=grafana&logoColor=orange&labelColor=F2F4F9" />
<img src="https://img.shields.io/badge/MySQL-005C84?style=for-the-badge&logo=mysql&logoColor=white" />
<img src="https://img.shields.io/badge/Swagger-85EA2D?style=for-the-badge&logo=Swagger&logoColor=white" />

</div>

## ‚úçÔ∏è Autores

<div align="center">

| **Gabriel Kazuki**                                                                                             |
|:-------------------------------------------------------------------------------------------------------------:|
| Desenvolvedor Full-Stack respons√°vel pela arquitetura e desenvolvimento do MetaScale.                          |
| [GitHub](https://github.com/GKazukiOnishi) ‚Ä¢ [LinkedIn](https://www.linkedin.com/in/gabriel-onishi)            |

| **Pedro Argentati**                                                                                            |
|:-------------------------------------------------------------------------------------------------------------:|
| Desenvolvedor Full-Stack respons√°vel pelo desenvolvimento do MetaScale.                                        |
| [GitHub](https://github.com/pedroargentati) ‚Ä¢ [LinkedIn](https://www.linkedin.com/in/pedro-argentati)          |

| **Breno de Souza**                                                                                             |
|:-------------------------------------------------------------------------------------------------------------:|
| Analista de dados respons√°vel pelo desenvolvimento de an√°lises e m√©tricas utilizando Grafana.                 |
| [GitHub](https://github.com/breno-souza) ‚Ä¢ [LinkedIn](https://www.linkedin.com/in/breno-souza)                 |

| **Rafael Tannous**                                                                                             |
|:-------------------------------------------------------------------------------------------------------------:|
| Analista de dados respons√°vel pelo desenvolvimento de an√°lises e m√©tricas utilizando Grafana.                 |
| [GitHub]([https://github.com/rafaeltannous](https://github.com/rafatannousfiap)) ‚Ä¢ [LinkedIn](https://www.linkedin.com/in/rafaeltannous/)            |

| **Felipe Otto**                                                                                                |
|:-------------------------------------------------------------------------------------------------------------:|
| Analista de Redes respons√°vel pela configura√ß√£o da VPC, EC2 e Load Balancer na AWS.                            |
| [GitHub](https://github.com/felipe-otto) ‚Ä¢ [LinkedIn](https://www.linkedin.com/in/felipe-otto)                 |

</div>


